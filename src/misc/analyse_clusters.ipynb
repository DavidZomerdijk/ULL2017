{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from os import path\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from dataset import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset (../../data/gold_deps.txt-t3000.pkl) from disk\n",
      "Dataset ready\n",
      "\tUnique verbs:\t712\n",
      "\tUnique verb-pos tags:\t32\n",
      "\tUnique verb-pos combinations:\t1546\n",
      "\tUnique nouns:\t1505\n",
      "\tUnique verb-noun pairs (train):\t900\n",
      "\tUnique verb-noun pairs (test):\t2563\n",
      "\tUnique intransitive subjects:\t115\n",
      "\tUnique transitive subjects:\t\t175\n",
      "\tUnique transitive objects:\t\t236\n",
      "\tUnique subject-object pairs:\t290\n",
      "\tEmbeddings for verbs:\t709\n",
      "\tEmbeddings for nouns:\t1438\n"
     ]
    }
   ],
   "source": [
    "data_path = path.join('../..', 'data')\n",
    "gold_corpus = path.join(data_path, 'gold_deps.txt')\n",
    "all_pairs = path.join(data_path, 'all_pairs')\n",
    "\n",
    "dataset = Dataset.load(gold_corpus, n_test_pairs=3000)\n",
    "\n",
    "clusters = pickle.load(open(\"clusters.pkl\", \"rb\"))\n",
    "# dataset = Dataset.load(gold_corpus, n_test_pairs=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "# Now determine which class occurs most often\n",
    "final_clusters = defaultdict(list)\n",
    "\n",
    "for verb in dataset.vs:\n",
    "    counts = []\n",
    "    for c in range(0,len(clusters)):\n",
    "        if verb in clusters[c]:\n",
    "            counts.append(clusters[c][verb])\n",
    "        else:\n",
    "            counts.append(0)\n",
    "    softmax_list = softmax(counts)\n",
    "    cluster = int(softmax_list.argmax(axis=0))\n",
    "    \n",
    "    if  isinstance(cluster ,int):\n",
    "\n",
    "        final_clusters[cluster].append( (verb ,softmax_list[cluster] ) )\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('manag', 0.17786139041215357),\n",
       " ('purchas', 0.17786139041215351),\n",
       " ('prohibit', 0.17786139041215351),\n",
       " ('propos', 0.15261275355154857),\n",
       " ('attract', 0.14738227392714331),\n",
       " ('sold', 0.12686675949144199),\n",
       " ('pick', 0.085700790577504793),\n",
       " ('advertis', 0.085700790577504793),\n",
       " ('encroach', 0.085700790577504793),\n",
       " ('toler', 0.085700790577504793),\n",
       " ('buck', 0.085700790577504793),\n",
       " ('swap', 0.085700790577504793),\n",
       " ('lengthen', 0.081296686356602532),\n",
       " ('record', 0.081296686356602532),\n",
       " ('calcul', 0.081296686356602532),\n",
       " ('averag', 0.081296686356602532),\n",
       " ('saw', 0.081296686356602532),\n",
       " ('inherit', 0.081296686356602532),\n",
       " ('repeal', 0.081296686356602532),\n",
       " ('constitut', 0.081296686356602532),\n",
       " ('dislik', 0.081296686356602532),\n",
       " ('slow', 0.081296686356602532),\n",
       " ('eye', 0.081296686356602532),\n",
       " ('spurn', 0.081296686356602532),\n",
       " ('understand', 0.081296686356602532),\n",
       " ('shed', 0.081296686356602532),\n",
       " ('handl', 0.081296686356602532),\n",
       " ('plan', 0.081296686356602532),\n",
       " ('induc', 0.081296686356602532),\n",
       " ('trim', 0.081296686356602532),\n",
       " ('doubl', 0.077323105561357963),\n",
       " ('special', 0.077323105561357963),\n",
       " ('examin', 0.077323105561357963),\n",
       " ('extend', 0.077323105561357963),\n",
       " ('grew', 0.073719861223678837),\n",
       " ('result', 0.073719861223678837),\n",
       " ('call', 0.073719861223678837),\n",
       " ('reach', 0.070437485670350269),\n",
       " ('keep', 0.070437485670350269),\n",
       " ('paid', 0.064677919190761601),\n",
       " ('expand', 0.064677919190761587),\n",
       " ('know', 0.064677919190761574),\n",
       " ('reduc', 0.062137475575784584),\n",
       " ('surg', 0.05558733488970443)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(final_clusters[4], key=lambda tup: tup[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from latentVectors import create_train_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Datasetc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a0d50709480a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDatasetc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Datasetc'"
     ]
    }
   ],
   "source": [
    "\n",
    "import theano\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from theano import sparse\n",
    "from main import Datasetc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = create_train_matrix(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = sparse.csc_matrix(name='x', dtype='int64')\n",
    "data, indices, indptr, shape = sparse.csm_properties(x)\n",
    "y = sparse.CSR(data, indices, indptr, shape)\n",
    "f = theano.function([x], y)\n",
    "# a = sp.csc_matrix(np.asarray([[0, 1, 1], [0, 0, 0], [1, 0, 0]]))\n",
    "a = sp.csc_matrix(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112257928"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for i in range(0,30):\n",
    "#     print(dataset.vs[dataset.train_VAE[i][0]], dataset.vps[dataset.train_VAE[i][1]], dataset.ns[dataset.train_VAE[i][2]])\n",
    "\n",
    "# for i in range(0,30):\n",
    "#     print(dataset.ys[i])\n",
    "    \n",
    "    \n",
    "def create_train_matrix(dataset):\n",
    "    shape_x_train = (len(dataset.ys), (len(dataset.vs) + len(dataset.ps) + len(dataset.ns)))\n",
    "    start_ps = len(dataset.vs) \n",
    "    start_ns = start_ps + len(dataset.ps)\n",
    "    \n",
    "    row = []\n",
    "    col = []\n",
    "    data = []\n",
    "    for  i, x in enumerate(dataset.ys):\n",
    "        col.append(x[2])\n",
    "        col.append(start_ps + x[3])\n",
    "        col.append(start_ns + x[1]) #add noun\n",
    "        #initialize other matrices\n",
    "        row.append(i)\n",
    "        row.append(i)\n",
    "        row.append(i)\n",
    "        data.append(1)\n",
    "        data.append(1)\n",
    "        data.append(1)\n",
    "        \n",
    "    mtx = sp.csc_matrix((data, (row, col)), shape=shape_x_train)\n",
    "    return mtx\n",
    "\n",
    "example = create_train_matrix(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 ..., 0 0 0]\n",
      " [0 1 0 ..., 0 0 0]\n",
      " [0 1 0 ..., 0 0 0]\n",
      " [0 0 1 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(example[1:5].toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 2249)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = [1,2,3]\n",
    "b= [4,5,6,7]\n",
    "c = [8,9,10,11]\n",
    "d = a + b + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[len(a) + len(b) + 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3],[4,5,6],[7,8,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [5],\n",
       "       [8]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
